{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f4b52d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the YOLOv8 model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/detect/mango_yolo/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# use your exact path\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      9\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, YOLOE, FastSAM, YOLOWorld\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\models\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastsam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NAS\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrtdetr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\models\\fastsam\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\models\\fastsam\\model.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\engine\\model.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Union\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcfg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\__init__.py:2064\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find torch_shm_manager at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path)\n\u001b[0;32m   2061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2064\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initExtension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_manager_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _manager_path\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;66;03m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:317\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m                 \u001b[38;5;66;03m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[0;32m    314\u001b[0m                 _queued_calls\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mcallable\u001b[39m, traceback\u001b[38;5;241m.\u001b[39mformat_stack()))\n\u001b[1;32m--> 317\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_check_capability\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m _lazy_call(_check_cubins)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDeferredCudaCallError\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m     _lazy_seed_tracker\u001b[38;5;241m.\u001b[39mqueue_seed(\u001b[38;5;28mcallable\u001b[39m, traceback\u001b[38;5;241m.\u001b[39mformat_stack())\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;66;03m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m     _queued_calls\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mcallable\u001b[39m, \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 366\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mline\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\linecache.py:136\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    137\u001b[0m         lines \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\tokenize.py:392\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopen\u001b[39m(filename):\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a file in read only mode using the encoding detected by\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    detect_encoding().\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m         encoding, lines \u001b[38;5;241m=\u001b[39m detect_encoding(buffer\u001b[38;5;241m.\u001b[39mreadline)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"runs/detect/mango_yolo/weights/best.pt\")  # use your exact path\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"YOLOv8 Detection\", annotated_frame)\n",
    "\n",
    "    # Exit with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e8158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 12 Mangos, 166.2ms\n",
      "Speed: 4.3ms preprocess, 166.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 257.8ms\n",
      "Speed: 4.7ms preprocess, 257.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 289.3ms\n",
      "Speed: 6.6ms preprocess, 289.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 315.5ms\n",
      "Speed: 7.2ms preprocess, 315.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 180.7ms\n",
      "Speed: 5.6ms preprocess, 180.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 149.2ms\n",
      "Speed: 3.0ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 186.9ms\n",
      "Speed: 3.2ms preprocess, 186.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 158.1ms\n",
      "Speed: 4.3ms preprocess, 158.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 113.0ms\n",
      "Speed: 3.7ms preprocess, 113.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 138.5ms\n",
      "Speed: 2.6ms preprocess, 138.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 128.6ms\n",
      "Speed: 4.5ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 140.1ms\n",
      "Speed: 3.3ms preprocess, 140.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 99.3ms\n",
      "Speed: 3.3ms preprocess, 99.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 170.7ms\n",
      "Speed: 2.9ms preprocess, 170.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 154.5ms\n",
      "Speed: 2.7ms preprocess, 154.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 144.5ms\n",
      "Speed: 4.0ms preprocess, 144.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 132.9ms\n",
      "Speed: 4.1ms preprocess, 132.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 116.6ms\n",
      "Speed: 3.5ms preprocess, 116.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 190.3ms\n",
      "Speed: 4.9ms preprocess, 190.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 136.6ms\n",
      "Speed: 3.7ms preprocess, 136.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 124.4ms\n",
      "Speed: 3.4ms preprocess, 124.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 244.4ms\n",
      "Speed: 4.3ms preprocess, 244.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 206.6ms\n",
      "Speed: 6.6ms preprocess, 206.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 250.5ms\n",
      "Speed: 4.9ms preprocess, 250.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 285.2ms\n",
      "Speed: 3.7ms preprocess, 285.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 267.3ms\n",
      "Speed: 4.1ms preprocess, 267.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 263.8ms\n",
      "Speed: 4.3ms preprocess, 263.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 276.5ms\n",
      "Speed: 4.8ms preprocess, 276.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 239.3ms\n",
      "Speed: 5.0ms preprocess, 239.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 246.8ms\n",
      "Speed: 2.6ms preprocess, 246.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 235.5ms\n",
      "Speed: 5.6ms preprocess, 235.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 263.0ms\n",
      "Speed: 5.1ms preprocess, 263.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 242.0ms\n",
      "Speed: 3.2ms preprocess, 242.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 260.8ms\n",
      "Speed: 5.0ms preprocess, 260.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 257.0ms\n",
      "Speed: 2.8ms preprocess, 257.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 197.8ms\n",
      "Speed: 3.3ms preprocess, 197.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 241.0ms\n",
      "Speed: 3.6ms preprocess, 241.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 257.3ms\n",
      "Speed: 3.3ms preprocess, 257.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 252.3ms\n",
      "Speed: 5.4ms preprocess, 252.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 245.8ms\n",
      "Speed: 11.0ms preprocess, 245.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 146.0ms\n",
      "Speed: 4.7ms preprocess, 146.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 258.8ms\n",
      "Speed: 6.4ms preprocess, 258.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 273.4ms\n",
      "Speed: 6.8ms preprocess, 273.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 163.5ms\n",
      "Speed: 6.9ms preprocess, 163.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 216.5ms\n",
      "Speed: 5.3ms preprocess, 216.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 288.7ms\n",
      "Speed: 5.3ms preprocess, 288.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 220.4ms\n",
      "Speed: 8.3ms preprocess, 220.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 227.1ms\n",
      "Speed: 4.2ms preprocess, 227.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 242.7ms\n",
      "Speed: 4.3ms preprocess, 242.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 245.6ms\n",
      "Speed: 4.8ms preprocess, 245.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 239.7ms\n",
      "Speed: 4.5ms preprocess, 239.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 234.9ms\n",
      "Speed: 4.5ms preprocess, 234.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 257.6ms\n",
      "Speed: 7.7ms preprocess, 257.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 200.8ms\n",
      "Speed: 4.2ms preprocess, 200.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 222.2ms\n",
      "Speed: 4.5ms preprocess, 222.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 239.7ms\n",
      "Speed: 3.2ms preprocess, 239.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 227.5ms\n",
      "Speed: 6.0ms preprocess, 227.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 259.1ms\n",
      "Speed: 5.7ms preprocess, 259.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 241.5ms\n",
      "Speed: 6.9ms preprocess, 241.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 211.1ms\n",
      "Speed: 3.6ms preprocess, 211.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 244.0ms\n",
      "Speed: 2.9ms preprocess, 244.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 237.5ms\n",
      "Speed: 3.1ms preprocess, 237.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 270.4ms\n",
      "Speed: 3.8ms preprocess, 270.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 264.4ms\n",
      "Speed: 3.3ms preprocess, 264.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 241.4ms\n",
      "Speed: 5.4ms preprocess, 241.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 241.5ms\n",
      "Speed: 3.0ms preprocess, 241.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 258.3ms\n",
      "Speed: 5.4ms preprocess, 258.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 233.0ms\n",
      "Speed: 3.0ms preprocess, 233.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 207.1ms\n",
      "Speed: 4.2ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 240.7ms\n",
      "Speed: 5.8ms preprocess, 240.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 Mangos, 170.0ms\n",
      "Speed: 3.2ms preprocess, 170.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 263.0ms\n",
      "Speed: 4.4ms preprocess, 263.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 256.9ms\n",
      "Speed: 4.2ms preprocess, 256.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 212.3ms\n",
      "Speed: 3.8ms preprocess, 212.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 218.5ms\n",
      "Speed: 3.8ms preprocess, 218.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 225.1ms\n",
      "Speed: 4.3ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 242.0ms\n",
      "Speed: 4.0ms preprocess, 242.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 230.5ms\n",
      "Speed: 4.7ms preprocess, 230.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 189.0ms\n",
      "Speed: 3.7ms preprocess, 189.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 221.4ms\n",
      "Speed: 4.5ms preprocess, 221.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 222.1ms\n",
      "Speed: 6.4ms preprocess, 222.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 235.4ms\n",
      "Speed: 2.7ms preprocess, 235.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 194.1ms\n",
      "Speed: 4.1ms preprocess, 194.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 252.1ms\n",
      "Speed: 3.2ms preprocess, 252.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 244.9ms\n",
      "Speed: 3.7ms preprocess, 244.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 222.7ms\n",
      "Speed: 4.2ms preprocess, 222.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 218.9ms\n",
      "Speed: 4.1ms preprocess, 218.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 230.7ms\n",
      "Speed: 2.7ms preprocess, 230.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 264.5ms\n",
      "Speed: 4.8ms preprocess, 264.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 256.2ms\n",
      "Speed: 5.8ms preprocess, 256.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 238.6ms\n",
      "Speed: 3.0ms preprocess, 238.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 297.1ms\n",
      "Speed: 5.5ms preprocess, 297.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 262.7ms\n",
      "Speed: 5.1ms preprocess, 262.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 260.3ms\n",
      "Speed: 4.8ms preprocess, 260.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 225.6ms\n",
      "Speed: 4.0ms preprocess, 225.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 235.7ms\n",
      "Speed: 4.7ms preprocess, 235.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 239.2ms\n",
      "Speed: 4.8ms preprocess, 239.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 186.1ms\n",
      "Speed: 4.3ms preprocess, 186.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 228.5ms\n",
      "Speed: 4.4ms preprocess, 228.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 240.5ms\n",
      "Speed: 4.5ms preprocess, 240.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 235.6ms\n",
      "Speed: 4.6ms preprocess, 235.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 276.4ms\n",
      "Speed: 6.2ms preprocess, 276.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 224.1ms\n",
      "Speed: 3.5ms preprocess, 224.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 235.3ms\n",
      "Speed: 4.6ms preprocess, 235.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 246.0ms\n",
      "Speed: 3.9ms preprocess, 246.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 250.7ms\n",
      "Speed: 4.3ms preprocess, 250.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 261.1ms\n",
      "Speed: 4.4ms preprocess, 261.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 235.9ms\n",
      "Speed: 5.2ms preprocess, 235.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 217.2ms\n",
      "Speed: 3.3ms preprocess, 217.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 240.5ms\n",
      "Speed: 3.6ms preprocess, 240.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 229.7ms\n",
      "Speed: 4.8ms preprocess, 229.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 266.1ms\n",
      "Speed: 4.7ms preprocess, 266.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 265.8ms\n",
      "Speed: 4.0ms preprocess, 265.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 214.0ms\n",
      "Speed: 5.1ms preprocess, 214.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 274.3ms\n",
      "Speed: 6.3ms preprocess, 274.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 239.6ms\n",
      "Speed: 2.9ms preprocess, 239.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 207.1ms\n",
      "Speed: 4.1ms preprocess, 207.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 186.7ms\n",
      "Speed: 3.2ms preprocess, 186.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 238.7ms\n",
      "Speed: 4.6ms preprocess, 238.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 193.5ms\n",
      "Speed: 3.7ms preprocess, 193.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 225.4ms\n",
      "Speed: 5.1ms preprocess, 225.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 212.8ms\n",
      "Speed: 4.1ms preprocess, 212.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 270.6ms\n",
      "Speed: 3.9ms preprocess, 270.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 244.9ms\n",
      "Speed: 4.1ms preprocess, 244.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 272.7ms\n",
      "Speed: 5.6ms preprocess, 272.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 238.3ms\n",
      "Speed: 2.8ms preprocess, 238.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 228.3ms\n",
      "Speed: 3.8ms preprocess, 228.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 239.0ms\n",
      "Speed: 4.6ms preprocess, 239.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 212.8ms\n",
      "Speed: 4.1ms preprocess, 212.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 256.2ms\n",
      "Speed: 5.6ms preprocess, 256.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 239.0ms\n",
      "Speed: 5.6ms preprocess, 239.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 248.0ms\n",
      "Speed: 3.8ms preprocess, 248.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 236.6ms\n",
      "Speed: 2.9ms preprocess, 236.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 228.7ms\n",
      "Speed: 5.9ms preprocess, 228.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 206.4ms\n",
      "Speed: 4.2ms preprocess, 206.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 227.1ms\n",
      "Speed: 6.0ms preprocess, 227.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 229.3ms\n",
      "Speed: 5.7ms preprocess, 229.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 228.3ms\n",
      "Speed: 3.2ms preprocess, 228.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Mangos, 190.6ms\n",
      "Speed: 2.8ms preprocess, 190.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 191.8ms\n",
      "Speed: 2.4ms preprocess, 191.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 212.7ms\n",
      "Speed: 3.1ms preprocess, 212.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 231.0ms\n",
      "Speed: 4.8ms preprocess, 231.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 244.4ms\n",
      "Speed: 4.5ms preprocess, 244.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 242.8ms\n",
      "Speed: 5.3ms preprocess, 242.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 255.5ms\n",
      "Speed: 4.2ms preprocess, 255.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 194.5ms\n",
      "Speed: 2.8ms preprocess, 194.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 248.7ms\n",
      "Speed: 4.3ms preprocess, 248.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 272.8ms\n",
      "Speed: 5.7ms preprocess, 272.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 278.5ms\n",
      "Speed: 4.5ms preprocess, 278.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 269.7ms\n",
      "Speed: 5.4ms preprocess, 269.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 240.2ms\n",
      "Speed: 4.3ms preprocess, 240.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 194.4ms\n",
      "Speed: 5.1ms preprocess, 194.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 175.1ms\n",
      "Speed: 3.4ms preprocess, 175.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 234.9ms\n",
      "Speed: 4.5ms preprocess, 234.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 263.7ms\n",
      "Speed: 4.6ms preprocess, 263.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 272.6ms\n",
      "Speed: 5.9ms preprocess, 272.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 261.2ms\n",
      "Speed: 3.5ms preprocess, 261.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 268.1ms\n",
      "Speed: 5.8ms preprocess, 268.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 257.9ms\n",
      "Speed: 2.5ms preprocess, 257.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 190.4ms\n",
      "Speed: 3.3ms preprocess, 190.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 240.3ms\n",
      "Speed: 3.3ms preprocess, 240.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 220.3ms\n",
      "Speed: 3.9ms preprocess, 220.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 253.1ms\n",
      "Speed: 4.1ms preprocess, 253.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 246.6ms\n",
      "Speed: 2.8ms preprocess, 246.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 178.8ms\n",
      "Speed: 5.2ms preprocess, 178.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 255.9ms\n",
      "Speed: 5.2ms preprocess, 255.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 259.9ms\n",
      "Speed: 3.1ms preprocess, 259.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 237.3ms\n",
      "Speed: 4.0ms preprocess, 237.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 246.5ms\n",
      "Speed: 3.8ms preprocess, 246.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 244.8ms\n",
      "Speed: 4.2ms preprocess, 244.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 176.8ms\n",
      "Speed: 3.1ms preprocess, 176.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 235.0ms\n",
      "Speed: 3.1ms preprocess, 235.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 184.1ms\n",
      "Speed: 3.1ms preprocess, 184.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 168.2ms\n",
      "Speed: 2.6ms preprocess, 168.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 207.4ms\n",
      "Speed: 3.4ms preprocess, 207.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 245.4ms\n",
      "Speed: 4.2ms preprocess, 245.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 222.1ms\n",
      "Speed: 3.8ms preprocess, 222.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 232.4ms\n",
      "Speed: 4.7ms preprocess, 232.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 241.5ms\n",
      "Speed: 4.7ms preprocess, 241.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 197.9ms\n",
      "Speed: 4.6ms preprocess, 197.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 245.3ms\n",
      "Speed: 8.2ms preprocess, 245.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 248.0ms\n",
      "Speed: 4.1ms preprocess, 248.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 271.3ms\n",
      "Speed: 5.3ms preprocess, 271.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 240.6ms\n",
      "Speed: 3.3ms preprocess, 240.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 261.2ms\n",
      "Speed: 2.7ms preprocess, 261.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 215.5ms\n",
      "Speed: 3.4ms preprocess, 215.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 258.4ms\n",
      "Speed: 4.0ms preprocess, 258.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 269.0ms\n",
      "Speed: 7.7ms preprocess, 269.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 253.6ms\n",
      "Speed: 3.7ms preprocess, 253.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 206.3ms\n",
      "Speed: 2.8ms preprocess, 206.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 246.1ms\n",
      "Speed: 3.0ms preprocess, 246.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 257.7ms\n",
      "Speed: 2.6ms preprocess, 257.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 258.7ms\n",
      "Speed: 4.4ms preprocess, 258.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 267.3ms\n",
      "Speed: 3.1ms preprocess, 267.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 248.4ms\n",
      "Speed: 2.7ms preprocess, 248.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 177.9ms\n",
      "Speed: 3.5ms preprocess, 177.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 201.1ms\n",
      "Speed: 3.1ms preprocess, 201.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 174.7ms\n",
      "Speed: 2.8ms preprocess, 174.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 191.1ms\n",
      "Speed: 3.4ms preprocess, 191.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 193.5ms\n",
      "Speed: 5.7ms preprocess, 193.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 212.6ms\n",
      "Speed: 4.4ms preprocess, 212.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 238.6ms\n",
      "Speed: 4.9ms preprocess, 238.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 188.6ms\n",
      "Speed: 5.6ms preprocess, 188.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 173.9ms\n",
      "Speed: 4.9ms preprocess, 173.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 229.4ms\n",
      "Speed: 2.7ms preprocess, 229.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 180.7ms\n",
      "Speed: 3.0ms preprocess, 180.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 268.7ms\n",
      "Speed: 5.3ms preprocess, 268.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 235.1ms\n",
      "Speed: 2.4ms preprocess, 235.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 145.6ms\n",
      "Speed: 3.6ms preprocess, 145.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 194.0ms\n",
      "Speed: 3.8ms preprocess, 194.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 259.4ms\n",
      "Speed: 3.3ms preprocess, 259.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 254.2ms\n",
      "Speed: 3.6ms preprocess, 254.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 260.1ms\n",
      "Speed: 3.0ms preprocess, 260.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 249.1ms\n",
      "Speed: 4.3ms preprocess, 249.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 272.1ms\n",
      "Speed: 4.6ms preprocess, 272.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 242.3ms\n",
      "Speed: 5.0ms preprocess, 242.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 150.6ms\n",
      "Speed: 5.2ms preprocess, 150.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 252.5ms\n",
      "Speed: 4.6ms preprocess, 252.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 243.7ms\n",
      "Speed: 2.8ms preprocess, 243.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 275.3ms\n",
      "Speed: 4.9ms preprocess, 275.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 264.1ms\n",
      "Speed: 3.4ms preprocess, 264.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 250.2ms\n",
      "Speed: 3.2ms preprocess, 250.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 225.6ms\n",
      "Speed: 5.2ms preprocess, 225.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 196.7ms\n",
      "Speed: 4.2ms preprocess, 196.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 229.9ms\n",
      "Speed: 4.7ms preprocess, 229.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 223.5ms\n",
      "Speed: 4.9ms preprocess, 223.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 254.7ms\n",
      "Speed: 5.1ms preprocess, 254.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 170.9ms\n",
      "Speed: 3.6ms preprocess, 170.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 244.8ms\n",
      "Speed: 4.1ms preprocess, 244.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 238.8ms\n",
      "Speed: 3.2ms preprocess, 238.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 129.4ms\n",
      "Speed: 3.0ms preprocess, 129.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 215.9ms\n",
      "Speed: 5.6ms preprocess, 215.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 258.4ms\n",
      "Speed: 2.5ms preprocess, 258.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 212.9ms\n",
      "Speed: 3.7ms preprocess, 212.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 242.5ms\n",
      "Speed: 4.4ms preprocess, 242.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 263.1ms\n",
      "Speed: 4.3ms preprocess, 263.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 176.4ms\n",
      "Speed: 4.0ms preprocess, 176.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 210.0ms\n",
      "Speed: 2.7ms preprocess, 210.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 173.7ms\n",
      "Speed: 2.7ms preprocess, 173.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 213.5ms\n",
      "Speed: 5.8ms preprocess, 213.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 243.0ms\n",
      "Speed: 5.3ms preprocess, 243.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 221.1ms\n",
      "Speed: 3.2ms preprocess, 221.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 249.6ms\n",
      "Speed: 3.8ms preprocess, 249.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 256.9ms\n",
      "Speed: 3.4ms preprocess, 256.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 296.6ms\n",
      "Speed: 5.3ms preprocess, 296.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 289.6ms\n",
      "Speed: 5.2ms preprocess, 289.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 156.3ms\n",
      "Speed: 5.5ms preprocess, 156.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 211.1ms\n",
      "Speed: 4.4ms preprocess, 211.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 284.7ms\n",
      "Speed: 6.1ms preprocess, 284.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 268.3ms\n",
      "Speed: 4.5ms preprocess, 268.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 243.6ms\n",
      "Speed: 4.3ms preprocess, 243.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 257.0ms\n",
      "Speed: 3.6ms preprocess, 257.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 224.5ms\n",
      "Speed: 6.9ms preprocess, 224.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 241.5ms\n",
      "Speed: 3.5ms preprocess, 241.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 176.8ms\n",
      "Speed: 4.4ms preprocess, 176.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 190.4ms\n",
      "Speed: 2.6ms preprocess, 190.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 168.1ms\n",
      "Speed: 2.6ms preprocess, 168.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 220.6ms\n",
      "Speed: 3.2ms preprocess, 220.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 220.8ms\n",
      "Speed: 3.0ms preprocess, 220.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 225.9ms\n",
      "Speed: 3.3ms preprocess, 225.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 226.8ms\n",
      "Speed: 4.3ms preprocess, 226.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 229.9ms\n",
      "Speed: 3.9ms preprocess, 229.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 246.1ms\n",
      "Speed: 2.5ms preprocess, 246.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 256.2ms\n",
      "Speed: 3.7ms preprocess, 256.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 262.2ms\n",
      "Speed: 3.9ms preprocess, 262.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 177.6ms\n",
      "Speed: 2.6ms preprocess, 177.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 224.3ms\n",
      "Speed: 4.2ms preprocess, 224.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 230.8ms\n",
      "Speed: 3.3ms preprocess, 230.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 256.9ms\n",
      "Speed: 2.7ms preprocess, 256.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 230.8ms\n",
      "Speed: 2.5ms preprocess, 230.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 270.5ms\n",
      "Speed: 5.2ms preprocess, 270.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 207.1ms\n",
      "Speed: 4.3ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 222.6ms\n",
      "Speed: 3.9ms preprocess, 222.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 152.4ms\n",
      "Speed: 5.1ms preprocess, 152.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 240.5ms\n",
      "Speed: 4.3ms preprocess, 240.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 246.4ms\n",
      "Speed: 4.1ms preprocess, 246.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 222.1ms\n",
      "Speed: 8.4ms preprocess, 222.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 251.8ms\n",
      "Speed: 4.6ms preprocess, 251.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 251.4ms\n",
      "Speed: 4.4ms preprocess, 251.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 190.0ms\n",
      "Speed: 3.4ms preprocess, 190.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 231.8ms\n",
      "Speed: 4.5ms preprocess, 231.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 239.4ms\n",
      "Speed: 5.2ms preprocess, 239.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 223.1ms\n",
      "Speed: 3.7ms preprocess, 223.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 203.7ms\n",
      "Speed: 3.0ms preprocess, 203.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 233.0ms\n",
      "Speed: 5.4ms preprocess, 233.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 221.3ms\n",
      "Speed: 2.4ms preprocess, 221.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 243.6ms\n",
      "Speed: 5.3ms preprocess, 243.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 248.7ms\n",
      "Speed: 3.7ms preprocess, 248.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 272.2ms\n",
      "Speed: 4.2ms preprocess, 272.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 208.3ms\n",
      "Speed: 3.1ms preprocess, 208.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 264.3ms\n",
      "Speed: 5.6ms preprocess, 264.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 217.2ms\n",
      "Speed: 4.8ms preprocess, 217.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 224.7ms\n",
      "Speed: 4.5ms preprocess, 224.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 265.1ms\n",
      "Speed: 5.7ms preprocess, 265.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 249.3ms\n",
      "Speed: 3.0ms preprocess, 249.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 225.1ms\n",
      "Speed: 3.1ms preprocess, 225.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 257.9ms\n",
      "Speed: 5.2ms preprocess, 257.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 247.9ms\n",
      "Speed: 6.1ms preprocess, 247.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 267.2ms\n",
      "Speed: 4.3ms preprocess, 267.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 226.0ms\n",
      "Speed: 3.4ms preprocess, 226.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 224.9ms\n",
      "Speed: 6.6ms preprocess, 224.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 214.0ms\n",
      "Speed: 4.3ms preprocess, 214.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 226.2ms\n",
      "Speed: 2.6ms preprocess, 226.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 157.7ms\n",
      "Speed: 7.4ms preprocess, 157.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 244.8ms\n",
      "Speed: 5.0ms preprocess, 244.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 266.6ms\n",
      "Speed: 4.4ms preprocess, 266.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 250.1ms\n",
      "Speed: 2.7ms preprocess, 250.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 264.3ms\n",
      "Speed: 3.1ms preprocess, 264.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 256.7ms\n",
      "Speed: 3.0ms preprocess, 256.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 259.2ms\n",
      "Speed: 4.6ms preprocess, 259.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 234.8ms\n",
      "Speed: 5.3ms preprocess, 234.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 190.7ms\n",
      "Speed: 2.2ms preprocess, 190.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 263.4ms\n",
      "Speed: 3.1ms preprocess, 263.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 220.3ms\n",
      "Speed: 2.5ms preprocess, 220.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 219.6ms\n",
      "Speed: 4.9ms preprocess, 219.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 260.4ms\n",
      "Speed: 3.4ms preprocess, 260.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 165.1ms\n",
      "Speed: 4.0ms preprocess, 165.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 256.2ms\n",
      "Speed: 5.3ms preprocess, 256.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 250.1ms\n",
      "Speed: 3.2ms preprocess, 250.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 271.1ms\n",
      "Speed: 4.4ms preprocess, 271.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 274.5ms\n",
      "Speed: 4.5ms preprocess, 274.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 258.2ms\n",
      "Speed: 2.9ms preprocess, 258.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 259.9ms\n",
      "Speed: 4.7ms preprocess, 259.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 239.4ms\n",
      "Speed: 3.4ms preprocess, 239.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 221.0ms\n",
      "Speed: 5.1ms preprocess, 221.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 232.9ms\n",
      "Speed: 4.4ms preprocess, 232.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 266.4ms\n",
      "Speed: 2.8ms preprocess, 266.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 225.2ms\n",
      "Speed: 3.8ms preprocess, 225.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 194.0ms\n",
      "Speed: 6.1ms preprocess, 194.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 252.1ms\n",
      "Speed: 6.7ms preprocess, 252.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 318.7ms\n",
      "Speed: 4.8ms preprocess, 318.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 252.7ms\n",
      "Speed: 3.8ms preprocess, 252.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 238.0ms\n",
      "Speed: 4.8ms preprocess, 238.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 251.0ms\n",
      "Speed: 4.3ms preprocess, 251.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 186.9ms\n",
      "Speed: 7.3ms preprocess, 186.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 195.9ms\n",
      "Speed: 2.7ms preprocess, 195.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 230.1ms\n",
      "Speed: 2.3ms preprocess, 230.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 236.5ms\n",
      "Speed: 3.2ms preprocess, 236.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 198.4ms\n",
      "Speed: 3.5ms preprocess, 198.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 239.1ms\n",
      "Speed: 4.5ms preprocess, 239.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 258.0ms\n",
      "Speed: 4.5ms preprocess, 258.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 253.2ms\n",
      "Speed: 3.6ms preprocess, 253.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 266.9ms\n",
      "Speed: 4.8ms preprocess, 266.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 225.5ms\n",
      "Speed: 5.2ms preprocess, 225.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 203.7ms\n",
      "Speed: 3.3ms preprocess, 203.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 229.8ms\n",
      "Speed: 4.2ms preprocess, 229.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 231.3ms\n",
      "Speed: 3.6ms preprocess, 231.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 179.7ms\n",
      "Speed: 3.3ms preprocess, 179.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 209.5ms\n",
      "Speed: 5.4ms preprocess, 209.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 217.0ms\n",
      "Speed: 4.2ms preprocess, 217.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 221.3ms\n",
      "Speed: 3.9ms preprocess, 221.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 265.1ms\n",
      "Speed: 3.5ms preprocess, 265.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 261.3ms\n",
      "Speed: 3.8ms preprocess, 261.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 237.9ms\n",
      "Speed: 3.9ms preprocess, 237.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 278.7ms\n",
      "Speed: 4.1ms preprocess, 278.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 228.0ms\n",
      "Speed: 2.7ms preprocess, 228.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 237.8ms\n",
      "Speed: 7.2ms preprocess, 237.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 180.6ms\n",
      "Speed: 4.6ms preprocess, 180.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 255.6ms\n",
      "Speed: 3.3ms preprocess, 255.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 208.3ms\n",
      "Speed: 3.5ms preprocess, 208.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 250.3ms\n",
      "Speed: 4.5ms preprocess, 250.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 283.6ms\n",
      "Speed: 6.0ms preprocess, 283.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 240.4ms\n",
      "Speed: 6.1ms preprocess, 240.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 218.9ms\n",
      "Speed: 3.8ms preprocess, 218.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 242.5ms\n",
      "Speed: 2.4ms preprocess, 242.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 245.4ms\n",
      "Speed: 3.1ms preprocess, 245.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 245.2ms\n",
      "Speed: 4.9ms preprocess, 245.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 229.0ms\n",
      "Speed: 5.5ms preprocess, 229.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 238.8ms\n",
      "Speed: 3.9ms preprocess, 238.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 190.8ms\n",
      "Speed: 4.3ms preprocess, 190.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 247.3ms\n",
      "Speed: 4.1ms preprocess, 247.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 239.0ms\n",
      "Speed: 2.5ms preprocess, 239.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 143.5ms\n",
      "Speed: 2.4ms preprocess, 143.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 248.3ms\n",
      "Speed: 4.6ms preprocess, 248.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 194.1ms\n",
      "Speed: 3.3ms preprocess, 194.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 235.8ms\n",
      "Speed: 4.1ms preprocess, 235.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 255.2ms\n",
      "Speed: 5.7ms preprocess, 255.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 219.1ms\n",
      "Speed: 5.6ms preprocess, 219.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 190.8ms\n",
      "Speed: 5.9ms preprocess, 190.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 212.2ms\n",
      "Speed: 4.4ms preprocess, 212.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 123.6ms\n",
      "Speed: 3.7ms preprocess, 123.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 224.8ms\n",
      "Speed: 3.1ms preprocess, 224.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 250.3ms\n",
      "Speed: 3.8ms preprocess, 250.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 254.2ms\n",
      "Speed: 3.6ms preprocess, 254.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 215.9ms\n",
      "Speed: 3.0ms preprocess, 215.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 262.9ms\n",
      "Speed: 3.7ms preprocess, 262.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 251.2ms\n",
      "Speed: 4.2ms preprocess, 251.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 249.6ms\n",
      "Speed: 3.5ms preprocess, 249.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 227.9ms\n",
      "Speed: 4.4ms preprocess, 227.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 223.3ms\n",
      "Speed: 4.3ms preprocess, 223.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 279.6ms\n",
      "Speed: 2.8ms preprocess, 279.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 266.0ms\n",
      "Speed: 5.9ms preprocess, 266.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 247.2ms\n",
      "Speed: 3.5ms preprocess, 247.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 276.4ms\n",
      "Speed: 4.1ms preprocess, 276.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 202.5ms\n",
      "Speed: 4.1ms preprocess, 202.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 222.2ms\n",
      "Speed: 3.8ms preprocess, 222.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 183.6ms\n",
      "Speed: 3.3ms preprocess, 183.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 230.1ms\n",
      "Speed: 4.2ms preprocess, 230.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 228.1ms\n",
      "Speed: 2.5ms preprocess, 228.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 247.8ms\n",
      "Speed: 5.6ms preprocess, 247.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 236.5ms\n",
      "Speed: 3.6ms preprocess, 236.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 238.9ms\n",
      "Speed: 3.7ms preprocess, 238.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 140.8ms\n",
      "Speed: 2.3ms preprocess, 140.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 249.3ms\n",
      "Speed: 3.1ms preprocess, 249.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 176.3ms\n",
      "Speed: 3.9ms preprocess, 176.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 110.8ms\n",
      "Speed: 3.1ms preprocess, 110.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 236.5ms\n",
      "Speed: 4.4ms preprocess, 236.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 144.2ms\n",
      "Speed: 2.8ms preprocess, 144.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 225.9ms\n",
      "Speed: 3.5ms preprocess, 225.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 247.2ms\n",
      "Speed: 2.8ms preprocess, 247.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 254.4ms\n",
      "Speed: 4.7ms preprocess, 254.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 279.1ms\n",
      "Speed: 5.8ms preprocess, 279.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 205.2ms\n",
      "Speed: 3.6ms preprocess, 205.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 288.4ms\n",
      "Speed: 3.6ms preprocess, 288.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 192.0ms\n",
      "Speed: 3.5ms preprocess, 192.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 202.4ms\n",
      "Speed: 3.2ms preprocess, 202.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 206.4ms\n",
      "Speed: 3.1ms preprocess, 206.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 235.2ms\n",
      "Speed: 4.8ms preprocess, 235.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 246.2ms\n",
      "Speed: 4.1ms preprocess, 246.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 250.4ms\n",
      "Speed: 3.6ms preprocess, 250.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 229.0ms\n",
      "Speed: 4.0ms preprocess, 229.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 275.7ms\n",
      "Speed: 2.7ms preprocess, 275.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 236.1ms\n",
      "Speed: 3.6ms preprocess, 236.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 148.9ms\n",
      "Speed: 4.1ms preprocess, 148.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 200.5ms\n",
      "Speed: 4.5ms preprocess, 200.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 262.7ms\n",
      "Speed: 4.7ms preprocess, 262.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 246.4ms\n",
      "Speed: 4.8ms preprocess, 246.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 203.9ms\n",
      "Speed: 4.0ms preprocess, 203.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 251.0ms\n",
      "Speed: 3.2ms preprocess, 251.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 149.0ms\n",
      "Speed: 5.3ms preprocess, 149.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 199.1ms\n",
      "Speed: 2.5ms preprocess, 199.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 164.2ms\n",
      "Speed: 2.9ms preprocess, 164.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 239.7ms\n",
      "Speed: 4.3ms preprocess, 239.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 209.3ms\n",
      "Speed: 3.3ms preprocess, 209.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 239.3ms\n",
      "Speed: 3.9ms preprocess, 239.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 231.6ms\n",
      "Speed: 4.2ms preprocess, 231.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 239.1ms\n",
      "Speed: 3.8ms preprocess, 239.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 259.2ms\n",
      "Speed: 3.4ms preprocess, 259.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 233.2ms\n",
      "Speed: 4.2ms preprocess, 233.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 232.9ms\n",
      "Speed: 5.8ms preprocess, 232.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 226.8ms\n",
      "Speed: 5.3ms preprocess, 226.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 194.8ms\n",
      "Speed: 5.4ms preprocess, 194.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 172.5ms\n",
      "Speed: 4.1ms preprocess, 172.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 117.9ms\n",
      "Speed: 2.9ms preprocess, 117.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 168.1ms\n",
      "Speed: 3.1ms preprocess, 168.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 181.5ms\n",
      "Speed: 3.6ms preprocess, 181.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 299.5ms\n",
      "Speed: 4.6ms preprocess, 299.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 295.8ms\n",
      "Speed: 6.2ms preprocess, 295.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 276.3ms\n",
      "Speed: 3.1ms preprocess, 276.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 282.5ms\n",
      "Speed: 6.1ms preprocess, 282.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 243.9ms\n",
      "Speed: 5.3ms preprocess, 243.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 224.2ms\n",
      "Speed: 4.9ms preprocess, 224.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 248.3ms\n",
      "Speed: 6.3ms preprocess, 248.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 245.4ms\n",
      "Speed: 3.6ms preprocess, 245.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 236.1ms\n",
      "Speed: 4.7ms preprocess, 236.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 195.7ms\n",
      "Speed: 6.1ms preprocess, 195.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 205.0ms\n",
      "Speed: 2.5ms preprocess, 205.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 235.9ms\n",
      "Speed: 4.5ms preprocess, 235.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 Mangos, 242.8ms\n",
      "Speed: 5.1ms preprocess, 242.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 243.2ms\n",
      "Speed: 3.6ms preprocess, 243.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 201.4ms\n",
      "Speed: 4.2ms preprocess, 201.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 203.9ms\n",
      "Speed: 3.7ms preprocess, 203.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 249.8ms\n",
      "Speed: 4.3ms preprocess, 249.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 268.1ms\n",
      "Speed: 4.8ms preprocess, 268.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 264.5ms\n",
      "Speed: 6.3ms preprocess, 264.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 226.9ms\n",
      "Speed: 2.8ms preprocess, 226.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 225.0ms\n",
      "Speed: 5.9ms preprocess, 225.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 Mangos, 223.6ms\n",
      "Speed: 4.5ms preprocess, 223.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 273.4ms\n",
      "Speed: 4.5ms preprocess, 273.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 Mangos, 255.8ms\n",
      "Speed: 4.2ms preprocess, 255.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 265.6ms\n",
      "Speed: 3.3ms preprocess, 265.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 264.6ms\n",
      "Speed: 3.8ms preprocess, 264.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 219.0ms\n",
      "Speed: 3.2ms preprocess, 219.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 216.9ms\n",
      "Speed: 3.7ms preprocess, 216.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 219.1ms\n",
      "Speed: 3.2ms preprocess, 219.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 229.0ms\n",
      "Speed: 3.4ms preprocess, 229.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 187.4ms\n",
      "Speed: 2.8ms preprocess, 187.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 241.9ms\n",
      "Speed: 5.1ms preprocess, 241.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 189.0ms\n",
      "Speed: 3.5ms preprocess, 189.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 Mangos, 254.7ms\n",
      "Speed: 3.8ms preprocess, 254.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 184.3ms\n",
      "Speed: 4.9ms preprocess, 184.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 204.9ms\n",
      "Speed: 2.5ms preprocess, 204.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 258.7ms\n",
      "Speed: 6.1ms preprocess, 258.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 Mangos, 221.8ms\n",
      "Speed: 3.7ms preprocess, 221.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 239.1ms\n",
      "Speed: 5.9ms preprocess, 239.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 Mangos, 262.8ms\n",
      "Speed: 3.2ms preprocess, 262.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 164.3ms\n",
      "Speed: 3.3ms preprocess, 164.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 242.0ms\n",
      "Speed: 3.3ms preprocess, 242.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 270.7ms\n",
      "Speed: 5.2ms preprocess, 270.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 257.6ms\n",
      "Speed: 5.9ms preprocess, 257.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 226.6ms\n",
      "Speed: 3.1ms preprocess, 226.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 Mangos, 219.9ms\n",
      "Speed: 3.2ms preprocess, 219.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 232.7ms\n",
      "Speed: 4.4ms preprocess, 232.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 241.4ms\n",
      "Speed: 5.5ms preprocess, 241.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 193.2ms\n",
      "Speed: 4.6ms preprocess, 193.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 263.1ms\n",
      "Speed: 3.2ms preprocess, 263.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 249.0ms\n",
      "Speed: 5.9ms preprocess, 249.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 Mangos, 276.5ms\n",
      "Speed: 7.1ms preprocess, 276.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 242.6ms\n",
      "Speed: 3.7ms preprocess, 242.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 217.6ms\n",
      "Speed: 4.8ms preprocess, 217.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 248.8ms\n",
      "Speed: 3.6ms preprocess, 248.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 242.8ms\n",
      "Speed: 4.3ms preprocess, 242.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 Mangos, 167.1ms\n",
      "Speed: 4.0ms preprocess, 167.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 211.6ms\n",
      "Speed: 2.9ms preprocess, 211.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 240.2ms\n",
      "Speed: 3.4ms preprocess, 240.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 219.9ms\n",
      "Speed: 2.9ms preprocess, 219.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 217.3ms\n",
      "Speed: 6.2ms preprocess, 217.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 207.7ms\n",
      "Speed: 3.3ms preprocess, 207.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 176.2ms\n",
      "Speed: 2.9ms preprocess, 176.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 244.7ms\n",
      "Speed: 3.5ms preprocess, 244.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 247.8ms\n",
      "Speed: 5.2ms preprocess, 247.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 232.0ms\n",
      "Speed: 3.4ms preprocess, 232.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 249.1ms\n",
      "Speed: 4.9ms preprocess, 249.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 218.4ms\n",
      "Speed: 4.4ms preprocess, 218.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 183.9ms\n",
      "Speed: 3.0ms preprocess, 183.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 202.8ms\n",
      "Speed: 4.2ms preprocess, 202.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 213.3ms\n",
      "Speed: 4.4ms preprocess, 213.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 239.8ms\n",
      "Speed: 4.3ms preprocess, 239.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Mangos, 233.8ms\n",
      "Speed: 5.6ms preprocess, 233.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 161.7ms\n",
      "Speed: 6.0ms preprocess, 161.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 83.9ms\n",
      "Speed: 3.6ms preprocess, 83.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 Mangos, 221.5ms\n",
      "Speed: 6.3ms preprocess, 221.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 Mangos, 239.5ms\n",
      "Speed: 4.8ms preprocess, 239.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOLOv8 Video Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, annotated_frame)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Save frame to output video\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(annotated_frame)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"runs/detect/mango_yolo/weights/best.pt\")\n",
    "\n",
    "# Load video\n",
    "video_path = \"mango_video.mp4\"  # Replace with your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define video writer to save output\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"output_with_boxes.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Inference\n",
    "    results = model(frame)\n",
    "\n",
    "    # Annotate frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"YOLOv8 Video Detection\", annotated_frame)\n",
    "\n",
    "    # Save frame to output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e3b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saira\\.cache\\huggingface\\hub\\models--facebook--detr-resnet-101. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cat with confidence 0.998 at location [344.06, 24.85, 640.34, 373.74]\n",
      "Detected remote with confidence 0.997 at location [328.13, 75.93, 372.81, 187.66]\n",
      "Detected remote with confidence 0.997 at location [39.34, 70.13, 175.56, 118.78]\n",
      "Detected cat with confidence 0.998 at location [15.36, 51.75, 316.89, 471.16]\n",
      "Detected couch with confidence 0.995 at location [-0.19, 0.71, 639.73, 474.17]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# initialize the model\n",
    "processor = DetrImageProcessor.from_pretrained(\n",
    "    \"facebook/detr-resnet-101\", revision=\"no_timm\"\n",
    ")\n",
    "model = DetrForObjectDetection.from_pretrained(\n",
    "    \"facebook/detr-resnet-101\", revision=\"no_timm\"\n",
    ")\n",
    "\n",
    "# preprocess the inputs and infer\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# non max supression above 0.9\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(\n",
    "    outputs, target_sizes=target_sizes, threshold=0.9\n",
    ")[0]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "        f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c364aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading image: No connection adapters were found for 'D:\\\\PS\\\\FruitPilot\\\\Object-detection\\x0crame_81_jpg.rf.ecae8437dff5d87f63a2486fd92fa61c.jpg'\n"
     ]
    }
   ],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont # Added ImageDraw and ImageFont\n",
    "import requests\n",
    "\n",
    "def draw_bounding_boxes_on_image():\n",
    "    \"\"\"\n",
    "    Fetches an image, performs object detection using a pre-trained DETR model,\n",
    "    draws bounding boxes and labels on the image, and saves the result.\n",
    "    \"\"\"\n",
    "    # URL of the image to process\n",
    "    url = \"D:\\PS\\FruitPilot\\Object-detection\\frame_81_jpg.rf.ecae8437dff5d87f63a2486fd92fa61c.jpg\"\n",
    "    \n",
    "    # Download and open the image\n",
    "    try:\n",
    "        image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "        return\n",
    "    except IOError:\n",
    "        print(f\"Error opening image. Please ensure the URL points to a valid image.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the image processor and model from Hugging Face Transformers\n",
    "    # Using DETR (DEtection TRansformer) model with a ResNet-101 backbone\n",
    "    # The \"no_timm\" revision is specified as in the original code\n",
    "    try:\n",
    "        processor = DetrImageProcessor.from_pretrained(\n",
    "            \"facebook/detr-resnet-101\", revision=\"no_timm\"\n",
    "        )\n",
    "        model = DetrForObjectDetection.from_pretrained(\n",
    "            \"facebook/detr-resnet-101\", revision=\"no_timm\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or processor: {e}\")\n",
    "        print(\"Please ensure you have an internet connection and the 'transformers' library is correctly installed.\")\n",
    "        return\n",
    "\n",
    "    # Preprocess the input image\n",
    "    # The processor prepares the image in the format expected by the model\n",
    "    # return_tensors=\"pt\" returns PyTorch tensors\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform inference\n",
    "    # The model outputs raw predictions (logits and bounding boxes)\n",
    "    with torch.no_grad(): # Disable gradient calculations for inference\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Convert outputs (bounding boxes and class logits) to COCO API format\n",
    "    # The model outputs coordinates in the format (center_x, center_y, width, height) relative to the image size.\n",
    "    # Post-processing converts these to (x_min, y_min, x_max, y_max) format.\n",
    "    # target_sizes expects [height, width]\n",
    "    target_sizes = torch.tensor([image.size[::-1]]) \n",
    "    \n",
    "    # Apply non-maximum suppression (NMS) with a threshold of 0.9\n",
    "    # NMS helps to remove duplicate or overlapping bounding boxes for the same object\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs, target_sizes=target_sizes, threshold=0.9\n",
    "    )[0] # We take the first result as we process a single image\n",
    "\n",
    "    # Create a drawable version of the image to draw on\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    "\n",
    "    # Attempt to load a font; use default if specific font is not found\n",
    "    try:\n",
    "        # You can specify a path to a .ttf font file if you have one\n",
    "        # font = ImageFont.truetype(\"arial.ttf\", 15) \n",
    "        font = ImageFont.load_default() # Using a default font for broader compatibility\n",
    "    except IOError:\n",
    "        print(\"Default font loaded. For custom font, ensure the .ttf file is accessible.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Define colors for bounding boxes and text\n",
    "    box_color = \"red\"\n",
    "    text_color = \"white\"\n",
    "    text_background_color = \"red\" # Background for text for better visibility\n",
    "\n",
    "    # Iterate over detected objects\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        # Get bounding box coordinates and round them\n",
    "        box_coords = [round(i) for i in box.tolist()] # [x_min, y_min, x_max, y_max]\n",
    "        \n",
    "        # Draw the bounding box rectangle\n",
    "        draw.rectangle(box_coords, outline=box_color, width=3)\n",
    "        \n",
    "        # Prepare the label text with class name and confidence score\n",
    "        label_name = model.config.id2label[label.item()]\n",
    "        confidence = round(score.item(), 3)\n",
    "        label_text = f\"{label_name}: {confidence}\"\n",
    "        \n",
    "        # Calculate text size to position it correctly\n",
    "        # For Pillow version >= 9.2.0, textbbox is preferred.\n",
    "        # For older versions, textsize was used. textbbox is more accurate.\n",
    "        try:\n",
    "            # Get bounding box of the text itself\n",
    "            text_bbox = draw.textbbox((0,0), label_text, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "        except AttributeError: # Fallback for older Pillow versions that don't have textbbox\n",
    "             # Note: textsize is less accurate than textbbox\n",
    "            text_size_result = draw.textsize(label_text, font=font) \n",
    "            text_width = text_size_result[0]\n",
    "            text_height = text_size_result[1]\n",
    "\n",
    "\n",
    "        # Determine position for the text (above the bounding box)\n",
    "        text_x = box_coords[0]\n",
    "        text_y = box_coords[1] - text_height - 5  # 5 pixels padding above the box\n",
    "\n",
    "        # Adjust text position if it goes off the top of the image\n",
    "        if text_y < 0:\n",
    "            text_y = box_coords[1] + 5  # Place it just inside the top of the box\n",
    "\n",
    "        # Draw a filled rectangle as a background for the text\n",
    "        draw.rectangle(\n",
    "            (text_x, text_y, text_x + text_width, text_y + text_height),\n",
    "            fill=text_background_color\n",
    "        )\n",
    "        \n",
    "        # Draw the text\n",
    "        draw.text((text_x, text_y), label_text, fill=text_color, font=font)\n",
    "\n",
    "    # Save the image with bounding boxes\n",
    "    output_image_path = \"image_with_bounding_boxes.jpg\"\n",
    "    try:\n",
    "        image_with_boxes.save(output_image_path)\n",
    "        print(f\"Image with bounding boxes saved to: {output_image_path}\")\n",
    "        \n",
    "        # Optionally, display the image if in an environment that supports it (e.g., Jupyter Notebook)\n",
    "        # image_with_boxes.show() \n",
    "        \n",
    "    except IOError:\n",
    "        print(f\"Error saving image to {output_image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while saving/showing the image: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    draw_bounding_boxes_on_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c470f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with bounding boxes saved to: D:\\PS\\FruitPilot\\Object-detection\\frame_81_jpg.rf.ecae8437dff5d87f63a2486fd92fa61c_with_boxes.jpg\n"
     ]
    }
   ],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os # Imported os module for path manipulation\n",
    "\n",
    "def draw_bounding_boxes_on_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image from a local path, performs object detection using a\n",
    "    pre-trained DETR model, draws bounding boxes and labels on the image,\n",
    "    and saves the result.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the local image file.\n",
    "    \"\"\"\n",
    "    # Open the local image\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{image_path}' was not found.\")\n",
    "        return\n",
    "    except IOError:\n",
    "        print(f\"Error opening image. Please ensure '{image_path}' is a valid image file.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while opening the image: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize the image processor and model from Hugging Face Transformers\n",
    "    # Using DETR (DEtection TRansformer) model with a ResNet-101 backbone\n",
    "    # The \"no_timm\" revision is specified as in the original code\n",
    "    try:\n",
    "        processor = DetrImageProcessor.from_pretrained(\n",
    "            \"facebook/detr-resnet-101\", revision=\"no_timm\"\n",
    "        )\n",
    "        model = DetrForObjectDetection.from_pretrained(\n",
    "            \"facebook/detr-resnet-101\", revision=\"no_timm\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or processor: {e}\")\n",
    "        print(\"Please ensure you have an internet connection and the 'transformers' library is correctly installed.\")\n",
    "        return\n",
    "\n",
    "    # Preprocess the input image\n",
    "    # The processor prepares the image in the format expected by the model\n",
    "    # return_tensors=\"pt\" returns PyTorch tensors\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform inference\n",
    "    # The model outputs raw predictions (logits and bounding boxes)\n",
    "    with torch.no_grad(): # Disable gradient calculations for inference\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Convert outputs (bounding boxes and class logits) to COCO API format\n",
    "    # The model outputs coordinates in the format (center_x, center_y, width, height) relative to the image size.\n",
    "    # Post-processing converts these to (x_min, y_min, x_max, y_max) format.\n",
    "    # target_sizes expects [height, width]\n",
    "    target_sizes = torch.tensor([image.size[::-1]]) \n",
    "    \n",
    "    # Apply non-maximum suppression (NMS) with a threshold of 0.9\n",
    "    # NMS helps to remove duplicate or overlapping bounding boxes for the same object\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs, target_sizes=target_sizes, threshold=0.9\n",
    "    )[0] # We take the first result as we process a single image\n",
    "\n",
    "    # Create a drawable version of the image to draw on\n",
    "    image_with_boxes = image.copy()\n",
    "    draw = ImageDraw.Draw(image_with_boxes)\n",
    "\n",
    "    # Attempt to load a font; use default if specific font is not found\n",
    "    try:\n",
    "        # You can specify a path to a .ttf font file if you have one\n",
    "        # font = ImageFont.truetype(\"arial.ttf\", 15) \n",
    "        font = ImageFont.load_default() # Using a default font for broader compatibility\n",
    "    except IOError:\n",
    "        print(\"Default font loaded. For custom font, ensure the .ttf file is accessible.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Define colors for bounding boxes and text\n",
    "    box_color = \"red\"\n",
    "    text_color = \"white\"\n",
    "    text_background_color = \"red\" # Background for text for better visibility\n",
    "\n",
    "    # Iterate over detected objects\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        # Get bounding box coordinates and round them\n",
    "        box_coords = [round(i) for i in box.tolist()] # [x_min, y_min, x_max, y_max]\n",
    "        \n",
    "        # Draw the bounding box rectangle\n",
    "        draw.rectangle(box_coords, outline=box_color, width=3)\n",
    "        \n",
    "        # Prepare the label text with class name and confidence score\n",
    "        label_name = model.config.id2label[label.item()]\n",
    "        confidence = round(score.item(), 3)\n",
    "        label_text = f\"{label_name}: {confidence}\"\n",
    "        \n",
    "        # Calculate text size to position it correctly\n",
    "        # For Pillow version >= 9.2.0, textbbox is preferred.\n",
    "        # For older versions, textsize was used. textbbox is more accurate.\n",
    "        try:\n",
    "            # Get bounding box of the text itself\n",
    "            text_bbox = draw.textbbox((0,0), label_text, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "        except AttributeError: # Fallback for older Pillow versions that don't have textbbox\n",
    "             # Note: textsize is less accurate than textbbox\n",
    "            text_size_result = draw.textsize(label_text, font=font) \n",
    "            text_width = text_size_result[0]\n",
    "            text_height = text_size_result[1]\n",
    "\n",
    "\n",
    "        # Determine position for the text (above the bounding box)\n",
    "        text_x = box_coords[0]\n",
    "        text_y = box_coords[1] - text_height - 5  # 5 pixels padding above the box\n",
    "\n",
    "        # Adjust text position if it goes off the top of the image\n",
    "        if text_y < 0:\n",
    "            text_y = box_coords[1] + 5  # Place it just inside the top of the box\n",
    "\n",
    "        # Draw a filled rectangle as a background for the text\n",
    "        draw.rectangle(\n",
    "            (text_x, text_y, text_x + text_width, text_y + text_height),\n",
    "            fill=text_background_color\n",
    "        )\n",
    "        \n",
    "        # Draw the text\n",
    "        draw.text((text_x, text_y), label_text, fill=text_color, font=font)\n",
    "\n",
    "    # Construct the output image path\n",
    "    base, ext = os.path.splitext(image_path)\n",
    "    output_image_path = f\"{base}_with_boxes{ext}\"\n",
    "    \n",
    "    # Save the image with bounding boxes\n",
    "    try:\n",
    "        image_with_boxes.save(output_image_path)\n",
    "        print(f\"Image with bounding boxes saved to: {output_image_path}\")\n",
    "        \n",
    "        # Optionally, display the image if in an environment that supports it (e.g., Jupyter Notebook)\n",
    "        # image_with_boxes.show() \n",
    "        \n",
    "    except IOError:\n",
    "        print(f\"Error saving image to {output_image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while saving/showing the image: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # IMPORTANT: Replace \"your_image.jpg\" with the actual path to your local image file.\n",
    "    # For example:\n",
    "    # On Windows: local_image_path = r\"C:\\Users\\YourUser\\Pictures\\my_image.png\"\n",
    "    # On macOS/Linux: local_image_path = \"/home/YourUser/Pictures/my_image.jpg\"\n",
    "    local_image_path = \"D:\\PS\\FruitPilot\\Object-detection\\\\frame_81_jpg.rf.ecae8437dff5d87f63a2486fd92fa61c.jpg\"  # <--- CHANGE THIS LINE\n",
    "\n",
    "    if local_image_path == \"your_image.jpg\":\n",
    "        print(\"Please update the 'local_image_path' variable in the script with the actual path to your image.\")\n",
    "    else:\n",
    "        draw_bounding_boxes_on_image(local_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a47df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
