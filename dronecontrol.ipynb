{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ae36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import threading\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dronekit import connect, VehicleMode, LocationGlobalRelative, APIException\n",
    "from flask import Flask, render_template, jsonify, request, Response\n",
    "from flask_socketio import SocketIO, emit\n",
    "from pymavlink import mavutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a2dec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Variables ---\n",
    "vehicle = None\n",
    "telemetry_data = {}\n",
    "update_interval = 1.0\n",
    "running = True  # Flag to control background threads\n",
    "\n",
    "# --- Computer Vision Variables ---\n",
    "cap = None  # Webcam capture object\n",
    "frame = None  # Current frame\n",
    "mango_detected = False\n",
    "mango_position = (0, 0)  # (x, y) center of detected mango\n",
    "frame_center = (0, 0)  # Will be calculated when webcam starts\n",
    "mango_tracking_active = False\n",
    "cv_lock = threading.Lock()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829157f7",
   "metadata": {},
   "source": [
    "## Connecting a vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e934a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to vehicle...\n",
      "Connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:autopilot:Arm: Need Position Estimate\n",
      "CRITICAL:autopilot:PreArm: Need Position Estimate\n"
     ]
    }
   ],
   "source": [
    "# Connect to vehicle\n",
    "print(\"Connecting to vehicle...\")\n",
    "vehicle = connect('tcp:127.0.0.1:5762', wait_ready=True)\n",
    "print(\"Connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34efa614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp39-cp39-win_amd64.whl (212.4 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.22.0-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.127-py3-none-any.whl (1.0 MB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saira\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.13.2)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\saira\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Collecting matplotlib>=3.3.0\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "Collecting py-cpuinfo\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pyyaml>=5.3.1\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Collecting requests>=2.23.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Using cached pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\saira\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Collecting scipy>=1.4.1\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saira\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.57.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\saira\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib>=3.3.0->ultralytics) (3.21.0)\n",
      "Installing collected packages: mpmath, sympy, fsspec, networkx, filelock, torch, pillow, torchvision, torchaudio, fonttools, contourpy, kiwisolver, pyparsing, cycler, importlib-resources, matplotlib, py-cpuinfo, pyyaml, tzdata, pytz, pandas, seaborn, ultralytics-thop, certifi, idna, charset-normalizer, urllib3, requests, scipy, tqdm, ultralytics\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 contourpy-1.3.0 cycler-0.12.1 filelock-3.18.0 fonttools-4.57.0 fsspec-2025.3.2 idna-3.10 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 mpmath-1.3.0 networkx-3.2.1 pandas-2.2.3 pillow-11.2.1 py-cpuinfo-9.0.0 pyparsing-3.2.3 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 scipy-1.13.1 seaborn-0.13.2 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 tqdm-4.67.1 tzdata-2025.2 ultralytics-8.3.127 ultralytics-thop-2.0.14 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b57ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8 model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # For YOLOv8, we need to use ultralytics package instead of torch.hub\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Load the YOLOv8 model\n",
    "    model = YOLO('predict_mango.pt')  # Load a custom model\n",
    "    \n",
    "    print(\"YOLOv8 model loaded successfully.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Error: PyTorch not found. Please install it (pip install torch torchvision torchaudio).\")\n",
    "    model = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a548a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_webcam():\n",
    "    global cap, frame_center\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        height, width = frame.shape[:2]\n",
    "        frame_center = (width // 2, height // 2)\n",
    "        results = model(frame)\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow(\"Objec detection model\", annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        # cap = cv2.VideoCapture(0)  # Use 0 for default webcam\n",
    "        # if not cap.isOpened():\n",
    "        #     print(\"Error: Could not open webcam.\")\n",
    "        #     return False\n",
    "        \n",
    "        # # Get webcam frame dimensions\n",
    "        # ret, test_frame = cap.read()\n",
    "        # if ret:\n",
    "        #     height, width = test_frame.shape[:2]\n",
    "        #     frame_center = (width // 2, height // 2)\n",
    "        #     print(f\"Webcam initialized. Frame size: {width}x{height}, Center: {frame_center}\")\n",
    "        #     return True\n",
    "        # else:\n",
    "        #     print(\"Error: Failed to read frame from webcam.\")\n",
    "        #     return False\n",
    "    \n",
    "    \n",
    "def detect_mango(image):\n",
    "    \"\"\"\n",
    "    Detect mangoes in the image using the YOLOv8 model.\n",
    "    Returns (success, center_x, center_y, width, height) of the first detected mango.\n",
    "    \"\"\"\n",
    "    global model, frame_center\n",
    "    if model is None:\n",
    "        print(\"YOLO model not loaded.\")\n",
    "        return False, 0, 0, 0, 0\n",
    "\n",
    "    try:\n",
    "        # Perform inference with YOLOv8\n",
    "        results = model(image, verbose=False)  # Suppress extra output\n",
    "        \n",
    "        # YOLOv8 returns a list of Results objects - get the first one\n",
    "        result = results[0] if results else None\n",
    "        \n",
    "        if result is None:\n",
    "            return False, 0, 0, 0, 0\n",
    "        \n",
    "        # Get all detections\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        # Check if any detections exist\n",
    "        if len(boxes) == 0:\n",
    "            return False, 0, 0, 0, 0\n",
    "            \n",
    "        # Find mango detections - YOLOv8 uses names in model.names\n",
    "        mango_detections = []\n",
    "        for i, box in enumerate(boxes):\n",
    "            # Get class id\n",
    "            cls_id = int(box.cls.item()) if hasattr(box, 'cls') else -1\n",
    "            # Check if this class is a mango\n",
    "            if cls_id >= 0 and cls_id < len(model.names) and 'mango' in model.names[cls_id].lower():\n",
    "                mango_detections.append(box)\n",
    "            \n",
    "        # If no mangoes found\n",
    "        if not mango_detections:\n",
    "            return False, 0, 0, 0, 0\n",
    "            \n",
    "        # Get first mango detection\n",
    "        mango_box = mango_detections[0]\n",
    "        \n",
    "        # Extract bounding box\n",
    "        x1, y1, x2, y2 = map(int, mango_box.xyxy[0].tolist())\n",
    "        \n",
    "        # Calculate center and dimensions\n",
    "        center_x = (x1 + x2) // 2\n",
    "        center_y = (y1 + y2) // 2\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        return True, center_x, center_y, width, height\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f9cbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam initialized. Frame size: 640x480, Center: (320, 240)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "786b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arm_and_takeoff(target_altitude):\n",
    "    print(\"Arming...\")\n",
    "    vehicle.mode = VehicleMode(\"GUIDED\")\n",
    "    vehicle.armed = True\n",
    "    while not vehicle.armed:\n",
    "        print(\" Waiting for arming...\")\n",
    "        time.sleep(1)\n",
    "    print(\"Taking off...\")\n",
    "    vehicle.simple_takeoff(target_altitude)\n",
    "    while True:\n",
    "        alt = vehicle.location.global_relative_frame.alt\n",
    "        print(f\" Altitude: {alt:.2f} m\")\n",
    "        if alt >= target_altitude * 0.95:\n",
    "            print(\"Reached target altitude.\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "def condition_yaw(heading, relative=True, yaw_speed=20):\n",
    "    is_relative = 1 if relative else 0\n",
    "    msg = vehicle.message_factory.command_long_encode(\n",
    "        0, 0,\n",
    "        mavutil.mavlink.MAV_CMD_CONDITION_YAW,\n",
    "        0,\n",
    "        heading, yaw_speed, 1, is_relative,\n",
    "        0, 0, 0\n",
    "    )\n",
    "    vehicle.send_mavlink(msg)\n",
    "    vehicle.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f3da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
